{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pickle import load\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import array, stack\n",
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn \n",
    "from torch import optim \n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load precoder dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dir_name, fading, num_ant, SNR_dB, bit_codebook):\n",
    "\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    file_name = f'{dir_name}/{fading}_precoder_data_{num_ant}_ant_SNR_{SNR_dB}dB_{bit_codebook}_bit_codebk'\n",
    "    print(file_name)\n",
    "    with open(f'{file_name}.pkl', 'rb') as f:\n",
    "        precoders, labels = load(f)\n",
    "    return precoders, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(precoders):\n",
    "    # test plots\n",
    "    for i in range(2):\n",
    "        plt.scatter(precoders[i][0::2], precoders[i][1::2])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precoder dataset class that packages the dataset into a format compatible with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrecoderDataset(Dataset):\n",
    "    def __init__(self, data, target, transform=None):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.target = torch.from_numpy(target).long()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        # define layers and activation function as class parameters\n",
    "        self.fc1 = nn.Linear(in_features=input_size, out_features=100)\n",
    "        self.fc2 = nn.Linear(in_features=100, out_features=100)\n",
    "        self.output = nn.Linear(in_features=100, out_features=output_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # define NN connections here, output of last layer is pred\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        pred = self.softmax(self.output(x))\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essential System Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 100000\n",
    "fading = 1\n",
    "num_ant = [2, 4]\n",
    "SNR_dB = [10, 20, 45]\n",
    "bit_codebook = [1, 2]\n",
    "visual = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_epochs = 100 # Number of times you go through the whole dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation iterations\n",
    "1. Load dataset\n",
    "2. Visualize, if necessary \n",
    "3. Create instance of precoder dataset class (Package dataset such that it is compatible for PyTorch)\n",
    "4. Split dataset into 80% training and 20% validation\n",
    "5. Create PyTorch dataloaders for training and validation data (Dataloaders divide the dataset into chuncks called batches. We can pass data to the neural network one batch at a time) \n",
    "6. Create an instance of neural network class\n",
    "7. Define the loss and optimizer\n",
    "8. Epoch - one pass of the entire dataset (training + validation)\n",
    "9. In each epoch you iterate over several batches (Batch - chunk of data that is fed to the neural network in one go) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======10 dB, 2 antennas, 1 bit codebook======\n",
      "datasets/1_precoder_data_2_ant_SNR_10dB_1_bit_codebk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utsa/.local/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, training loss: 0.60073942, training accuracy: 88.0175%, validation loss: 0.47842523, validation accuracy: 93.46%\n",
      "Epoch 2, training loss: 0.42622018, training accuracy: 93.21625%, validation loss: 0.39937568, validation accuracy: 93.515%\n",
      "Epoch 3, training loss: 0.39346686, training accuracy: 93.22500000000001%, validation loss: 0.38729531, validation accuracy: 93.52000000000001%\n",
      "Epoch 4, training loss: 0.38648704, training accuracy: 93.23625%, validation loss: 0.38328043, validation accuracy: 93.535%\n",
      "Epoch 5, training loss: 0.38371748, training accuracy: 93.24125%, validation loss: 0.38111037, validation accuracy: 93.535%\n",
      "Epoch 6, training loss: 0.38225582, training accuracy: 93.26375%, validation loss: 0.38033926, validation accuracy: 93.515%\n",
      "Epoch 7, training loss: 0.38137954, training accuracy: 93.2375%, validation loss: 0.37941644, validation accuracy: 93.55%\n",
      "Epoch 8, training loss: 0.38078409, training accuracy: 93.24375%, validation loss: 0.37874162, validation accuracy: 93.535%\n",
      "Epoch 9, training loss: 0.38036567, training accuracy: 93.2475%, validation loss: 0.37820140, validation accuracy: 93.545%\n",
      "Epoch 10, training loss: 0.38005263, training accuracy: 93.26124999999999%, validation loss: 0.37810341, validation accuracy: 93.565%\n",
      "Epoch 11, training loss: 0.37981620, training accuracy: 93.255%, validation loss: 0.37781331, validation accuracy: 93.57%\n",
      "Epoch 12, training loss: 0.37962601, training accuracy: 93.27%, validation loss: 0.37771556, validation accuracy: 93.56%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-207-1012c1e597a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mtraining_total_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mtraining_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;31m# extracted from the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for SNR in SNR_dB:\n",
    "    for ant in num_ant:\n",
    "        for bit in bit_codebook:\n",
    "            print(f'======{SNR} dB, {ant} antennas, {bit} bit codebook======')\n",
    "            \n",
    "            precoders, labels = load_dataset('datasets', fading, ant, SNR, bit)\n",
    "            if visual == 1:\n",
    "                visualize(precoders)\n",
    "\n",
    "            precoder_data = stack(precoders, axis=0)\n",
    "            precoder_labels = array(labels)    \n",
    "\n",
    "            precoder_dataset = PrecoderDataset(precoder_data, precoder_labels)\n",
    "            train, val = random_split(precoder_dataset, [int(0.8*max_iter), int(0.2*max_iter)])\n",
    "            train_loader = DataLoader(train, batch_size=128, shuffle=True, num_workers=0)\n",
    "            val_loader = DataLoader(val, batch_size=128, shuffle=True, num_workers=0)\n",
    "            \n",
    "            num_classes = 2**bit\n",
    "            nn_input_size = 2*ant*ant\n",
    "            nn_output_size = num_classes\n",
    "            \n",
    "            model = Model(nn_input_size, nn_output_size)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                model.cuda()\n",
    "\n",
    "            optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "            # optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            loss = nn.CrossEntropyLoss()\n",
    "            for epoch in range(num_epochs):\n",
    "\n",
    "                # TRAINING\n",
    "                model.train()\n",
    "                training_total_correct = 0\n",
    "                training_losses = list()\n",
    "                for batch in train_loader:\n",
    "\n",
    "                    x, y = batch # extracted from the batch \n",
    "\n",
    "                    if torch.cuda.is_available():\n",
    "                        x = x.cuda()\n",
    "                        y = y.cuda()\n",
    "\n",
    "                    # step 1: forward pass \n",
    "                    prob = model(x) \n",
    "\n",
    "                    output = prob\n",
    "                    target = y\n",
    "\n",
    "                    # step 2: compute objective function - measuring distance between the output of the network vs actual answer \n",
    "                    obj_func = loss(output, target)\n",
    "\n",
    "                    # step 3: clear the gradients \n",
    "                    model.zero_grad()\n",
    "\n",
    "                    # step 4: accumulate partial derivatives of obj_func wrt parameters \n",
    "                    obj_func.backward()\n",
    "\n",
    "                    # step 5: step in the opposite direction of the gradient \n",
    "                    optimizer.step()\n",
    "\n",
    "                    training_losses.append(obj_func.item())\n",
    "\n",
    "                    max_prob, max_ind = torch.max(output, 1)\n",
    "                    for ind in range(len(max_ind)):\n",
    "                        if torch.equal(max_ind[ind], y[ind]):\n",
    "                            training_total_correct += 1    \n",
    "\n",
    "                # VALIDATION\n",
    "                model.eval()\n",
    "\n",
    "                validation_total_correct = 0\n",
    "                validation_losses = list()\n",
    "                for batch in val_loader:\n",
    "\n",
    "                    x, y = batch # extracted from the batch \n",
    "\n",
    "                    if torch.cuda.is_available():\n",
    "                        x = x.cuda()\n",
    "                        y = y.cuda()\n",
    "\n",
    "                    # step 1: forward pass \n",
    "                    with torch.no_grad():\n",
    "                        prob = model(x) \n",
    "\n",
    "                    output = prob\n",
    "                    target = y\n",
    "\n",
    "                    # step 2: compute objective function - measuring distance between the output of the network vs actual answer \n",
    "                    obj_func = loss(output, target)\n",
    "                    validation_losses.append(obj_func.item())\n",
    "\n",
    "                    max_prob, max_ind = torch.max(output, 1)\n",
    "\n",
    "                    for ind in range(len(max_ind)):\n",
    "                        if torch.equal(max_ind[ind], y[ind]):\n",
    "                            validation_total_correct += 1\n",
    "                training_accuracy = (training_total_correct/len(train))*100  \n",
    "                validation_accuracy = (validation_total_correct/len(val))*100   \n",
    "\n",
    "                print(f'Epoch {epoch + 1}, training loss: {torch.tensor(training_losses).mean():.8f}, training accuracy: {training_accuracy}%, validation loss: {torch.tensor(validation_losses).mean():.8f}, validation accuracy: {validation_accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
