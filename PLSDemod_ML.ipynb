{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pickle import load\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import array, stack\n",
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn \n",
    "from torch import optim \n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essential System Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "fading = 1\n",
    "num_ant = 2\n",
    "max_iter = 100000\n",
    "SNR_dB = 5\n",
    "bit_codebook = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load precoder dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/1_precoder_data_2_ant_SNR_5dB_2_bit_codebk\n"
     ]
    }
   ],
   "source": [
    "dir_name = 'datasets'\n",
    "if not os.path.exists(dir_name):\n",
    "    os.makedirs(dir_name)\n",
    "file_name = f'{dir_name}/{fading}_precoder_data_{num_ant}_ant_SNR_{SNR_dB}dB_{bit_codebook}_bit_codebk'\n",
    "print(file_name)\n",
    "with open(f'{file_name}.pkl', 'rb') as f:\n",
    "    precoders, labels = load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test plots\n",
    "for i in range(2):\n",
    "    plt.scatter(precoders[i][0::2], precoders[i][1::2])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precoder Dataset Class \n",
    "1. Package dataset such that it is compatible for PyTorch\n",
    "2. Split dataset into 80% training and 20% validation\n",
    "3. Create PyTorch dataloaders for training and validation data\n",
    "\n",
    "Dataloaders divide the dataset into chincks called batches. We can pass data to the neural network one batch at a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrecoderDataset(Dataset):\n",
    "    def __init__(self, data, target, transform=None):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.target = torch.from_numpy(target).long()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "precoder_data = stack(precoders, axis=0)\n",
    "precoder_labels = array(labels)    \n",
    "\n",
    "precoder_dataset = PrecoderDataset(precoder_data, precoder_labels)\n",
    "train, val = random_split(precoder_dataset, [int(0.8*max_iter), int(0.2*max_iter)])\n",
    "train_loader = DataLoader(train, batch_size=128, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val, batch_size=128, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_classes = 2**bit_codebook\n",
    "nn_input_size = 2*num_ant*num_ant\n",
    "nn_output_size = num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network \n",
    "1. Define Neural Network Class and create an instance of it\n",
    "2. Define the loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        # define layers and activation function as class parameters\n",
    "        self.fc1 = nn.Linear(in_features=input_size, out_features=50)\n",
    "        self.fc2 = nn.Linear(in_features=50, out_features=50)\n",
    "        self.output = nn.Linear(in_features=50, out_features=output_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # define NN connections here, output of last layer is pred\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        pred = self.output(x)\n",
    "        return pred\n",
    "\n",
    "\n",
    "model = Model(nn_input_size, nn_output_size)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training iterations\n",
    "1. Epoch - one pass of the entire dataset (training + validation). \n",
    "2. In each epoch you iterate over several batches.\n",
    "3. Batch - chunk of data that is fed to the neural network in one go. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, training loss: 1.15499008, training accuracy: 48.45375%, validation loss: 1.14761531, validation accuracy: 48.655%\n",
      "Epoch 2, training loss: 1.13577557, training accuracy: 48.97375%, validation loss: 1.14482725, validation accuracy: 48.69%\n",
      "Epoch 3, training loss: 1.13416409, training accuracy: 49.0525%, validation loss: 1.14344299, validation accuracy: 48.725%\n",
      "Epoch 4, training loss: 1.13360941, training accuracy: 49.0625%, validation loss: 1.14199519, validation accuracy: 48.64%\n",
      "Epoch 5, training loss: 1.13338065, training accuracy: 49.13625%, validation loss: 1.14262819, validation accuracy: 48.745%\n",
      "Epoch 6, training loss: 1.13254154, training accuracy: 49.11125%, validation loss: 1.14226735, validation accuracy: 48.71%\n",
      "Epoch 7, training loss: 1.13243365, training accuracy: 49.03125%, validation loss: 1.14384866, validation accuracy: 48.665000000000006%\n",
      "Epoch 8, training loss: 1.13231862, training accuracy: 49.02125%, validation loss: 1.14357996, validation accuracy: 48.745%\n",
      "Epoch 9, training loss: 1.13204467, training accuracy: 49.017500000000005%, validation loss: 1.14398909, validation accuracy: 48.735%\n",
      "Epoch 10, training loss: 1.13205349, training accuracy: 49.11375%, validation loss: 1.14211333, validation accuracy: 48.785000000000004%\n",
      "Epoch 11, training loss: 1.13223732, training accuracy: 49.16375%, validation loss: 1.14214694, validation accuracy: 48.725%\n",
      "Epoch 12, training loss: 1.13221812, training accuracy: 49.075%, validation loss: 1.14333606, validation accuracy: 48.69%\n",
      "Epoch 13, training loss: 1.13199043, training accuracy: 49.1225%, validation loss: 1.14299142, validation accuracy: 48.72%\n",
      "Epoch 14, training loss: 1.13197863, training accuracy: 49.105%, validation loss: 1.14343596, validation accuracy: 48.675000000000004%\n",
      "Epoch 15, training loss: 1.13211060, training accuracy: 49.17%, validation loss: 1.14262259, validation accuracy: 48.72%\n",
      "Epoch 16, training loss: 1.13203275, training accuracy: 49.12375%, validation loss: 1.14268661, validation accuracy: 48.72%\n",
      "Epoch 17, training loss: 1.13206971, training accuracy: 49.198750000000004%, validation loss: 1.14167798, validation accuracy: 48.805%\n",
      "Epoch 18, training loss: 1.13214540, training accuracy: 48.9625%, validation loss: 1.14266288, validation accuracy: 48.72%\n",
      "Epoch 19, training loss: 1.13228798, training accuracy: 49.12375%, validation loss: 1.14361262, validation accuracy: 48.805%\n",
      "Epoch 20, training loss: 1.13178813, training accuracy: 49.11125%, validation loss: 1.14395297, validation accuracy: 48.625%\n",
      "Epoch 21, training loss: 1.13181794, training accuracy: 49.17%, validation loss: 1.14373660, validation accuracy: 48.84%\n",
      "Epoch 22, training loss: 1.13149321, training accuracy: 49.09%, validation loss: 1.14293599, validation accuracy: 48.754999999999995%\n",
      "Epoch 23, training loss: 1.13161373, training accuracy: 49.1025%, validation loss: 1.14383864, validation accuracy: 48.78%\n",
      "Epoch 24, training loss: 1.13167894, training accuracy: 49.16625%, validation loss: 1.14299703, validation accuracy: 48.77%\n",
      "Epoch 25, training loss: 1.13172603, training accuracy: 49.14%, validation loss: 1.14372909, validation accuracy: 48.480000000000004%\n",
      "Epoch 26, training loss: 1.13155854, training accuracy: 49.16625%, validation loss: 1.14326203, validation accuracy: 48.575%\n",
      "Epoch 27, training loss: 1.13204205, training accuracy: 49.02%, validation loss: 1.14264834, validation accuracy: 48.735%\n",
      "Epoch 28, training loss: 1.13143206, training accuracy: 49.114999999999995%, validation loss: 1.14260340, validation accuracy: 48.84%\n",
      "Epoch 29, training loss: 1.13139820, training accuracy: 49.121249999999996%, validation loss: 1.14308190, validation accuracy: 48.809999999999995%\n",
      "Epoch 30, training loss: 1.13174760, training accuracy: 49.114999999999995%, validation loss: 1.14387095, validation accuracy: 48.699999999999996%\n",
      "Epoch 31, training loss: 1.13159573, training accuracy: 49.15625%, validation loss: 1.14212370, validation accuracy: 48.82%\n",
      "Epoch 32, training loss: 1.13166332, training accuracy: 49.12375%, validation loss: 1.14170027, validation accuracy: 48.805%\n",
      "Epoch 33, training loss: 1.13171029, training accuracy: 49.16375%, validation loss: 1.14195180, validation accuracy: 48.775%\n",
      "Epoch 34, training loss: 1.13135290, training accuracy: 49.16%, validation loss: 1.14216781, validation accuracy: 48.730000000000004%\n",
      "Epoch 35, training loss: 1.13148689, training accuracy: 49.2125%, validation loss: 1.14392495, validation accuracy: 48.78%\n",
      "Epoch 36, training loss: 1.13143587, training accuracy: 49.135%, validation loss: 1.14287674, validation accuracy: 48.775%\n",
      "Epoch 37, training loss: 1.13141620, training accuracy: 49.12875%, validation loss: 1.14171863, validation accuracy: 48.715%\n",
      "Epoch 38, training loss: 1.13127410, training accuracy: 49.1425%, validation loss: 1.14292979, validation accuracy: 48.735%\n",
      "Epoch 39, training loss: 1.13156140, training accuracy: 49.21375%, validation loss: 1.14179873, validation accuracy: 48.55%\n",
      "Epoch 40, training loss: 1.13114750, training accuracy: 49.1725%, validation loss: 1.14293230, validation accuracy: 48.685%\n",
      "Epoch 41, training loss: 1.13137269, training accuracy: 49.1375%, validation loss: 1.14323354, validation accuracy: 48.515%\n",
      "Epoch 42, training loss: 1.13132203, training accuracy: 49.205%, validation loss: 1.14341688, validation accuracy: 48.72%\n",
      "Epoch 43, training loss: 1.13109732, training accuracy: 49.13125%, validation loss: 1.14164996, validation accuracy: 48.65%\n",
      "Epoch 44, training loss: 1.13131511, training accuracy: 49.245%, validation loss: 1.14187241, validation accuracy: 48.705%\n",
      "Epoch 45, training loss: 1.13117135, training accuracy: 49.09375%, validation loss: 1.14403796, validation accuracy: 48.765%\n",
      "Epoch 46, training loss: 1.13120759, training accuracy: 49.11375%, validation loss: 1.14375079, validation accuracy: 48.58%\n",
      "Epoch 47, training loss: 1.13129413, training accuracy: 49.067499999999995%, validation loss: 1.14175546, validation accuracy: 48.69%\n",
      "Epoch 48, training loss: 1.13098085, training accuracy: 49.21125%, validation loss: 1.14350200, validation accuracy: 48.6%\n",
      "Epoch 49, training loss: 1.13119590, training accuracy: 49.1725%, validation loss: 1.14290535, validation accuracy: 48.620000000000005%\n",
      "Epoch 50, training loss: 1.13101840, training accuracy: 49.207499999999996%, validation loss: 1.14412999, validation accuracy: 48.5%\n",
      "Epoch 51, training loss: 1.13104415, training accuracy: 49.152499999999996%, validation loss: 1.14465141, validation accuracy: 48.735%\n",
      "Epoch 52, training loss: 1.13107240, training accuracy: 49.16875%, validation loss: 1.14415574, validation accuracy: 48.535000000000004%\n",
      "Epoch 53, training loss: 1.13134956, training accuracy: 49.198750000000004%, validation loss: 1.14260650, validation accuracy: 48.754999999999995%\n",
      "Epoch 54, training loss: 1.13118911, training accuracy: 49.15875%, validation loss: 1.14227533, validation accuracy: 48.809999999999995%\n",
      "Epoch 55, training loss: 1.13127017, training accuracy: 49.16375%, validation loss: 1.14273417, validation accuracy: 48.66%\n",
      "Epoch 56, training loss: 1.13127387, training accuracy: 49.19625%, validation loss: 1.14448750, validation accuracy: 48.66%\n",
      "Epoch 57, training loss: 1.13134801, training accuracy: 49.155%, validation loss: 1.14331865, validation accuracy: 48.785000000000004%\n",
      "Epoch 58, training loss: 1.13105154, training accuracy: 49.2125%, validation loss: 1.14281690, validation accuracy: 48.485%\n",
      "Epoch 59, training loss: 1.13131917, training accuracy: 49.0475%, validation loss: 1.14259052, validation accuracy: 48.78%\n",
      "Epoch 60, training loss: 1.13112640, training accuracy: 49.20125%, validation loss: 1.14399576, validation accuracy: 48.61%\n",
      "Epoch 61, training loss: 1.13100255, training accuracy: 49.214999999999996%, validation loss: 1.14301932, validation accuracy: 48.79%\n",
      "Epoch 62, training loss: 1.13099682, training accuracy: 49.2725%, validation loss: 1.14194930, validation accuracy: 48.74%\n",
      "Epoch 63, training loss: 1.13103032, training accuracy: 49.21375%, validation loss: 1.14349926, validation accuracy: 48.835%\n",
      "Epoch 64, training loss: 1.13105428, training accuracy: 49.214999999999996%, validation loss: 1.14186549, validation accuracy: 48.809999999999995%\n",
      "Epoch 65, training loss: 1.13109374, training accuracy: 49.120000000000005%, validation loss: 1.14278615, validation accuracy: 48.730000000000004%\n",
      "Epoch 66, training loss: 1.13089097, training accuracy: 49.15875%, validation loss: 1.14322364, validation accuracy: 48.605%\n",
      "Epoch 67, training loss: 1.13097382, training accuracy: 49.19625%, validation loss: 1.14276922, validation accuracy: 48.655%\n",
      "Epoch 68, training loss: 1.13085532, training accuracy: 49.205%, validation loss: 1.14197016, validation accuracy: 48.67%\n",
      "Epoch 69, training loss: 1.13094974, training accuracy: 49.29125%, validation loss: 1.14781868, validation accuracy: 48.6%\n",
      "Epoch 70, training loss: 1.13084745, training accuracy: 49.20375%, validation loss: 1.14496374, validation accuracy: 48.685%\n",
      "Epoch 71, training loss: 1.13113439, training accuracy: 49.11%, validation loss: 1.14239597, validation accuracy: 48.635%\n",
      "Epoch 72, training loss: 1.13107193, training accuracy: 49.16125%, validation loss: 1.14188850, validation accuracy: 48.575%\n",
      "Epoch 73, training loss: 1.13094020, training accuracy: 49.217499999999994%, validation loss: 1.14312363, validation accuracy: 48.730000000000004%\n",
      "Epoch 74, training loss: 1.13096166, training accuracy: 49.25%, validation loss: 1.14361739, validation accuracy: 48.775%\n",
      "Epoch 75, training loss: 1.13105345, training accuracy: 49.175000000000004%, validation loss: 1.14402747, validation accuracy: 48.725%\n",
      "Epoch 76, training loss: 1.13101029, training accuracy: 49.207499999999996%, validation loss: 1.14412796, validation accuracy: 48.585%\n",
      "Epoch 77, training loss: 1.13088357, training accuracy: 49.155%, validation loss: 1.14279246, validation accuracy: 48.735%\n",
      "Epoch 78, training loss: 1.13086069, training accuracy: 49.1925%, validation loss: 1.14271021, validation accuracy: 48.76%\n",
      "Epoch 79, training loss: 1.13066506, training accuracy: 49.1375%, validation loss: 1.14353931, validation accuracy: 48.675000000000004%\n",
      "Epoch 80, training loss: 1.13092816, training accuracy: 49.1675%, validation loss: 1.14499021, validation accuracy: 48.605%\n",
      "Epoch 81, training loss: 1.13071215, training accuracy: 49.17875%, validation loss: 1.14298177, validation accuracy: 48.75%\n",
      "Epoch 82, training loss: 1.13078129, training accuracy: 49.18125%, validation loss: 1.14257348, validation accuracy: 48.72%\n",
      "Epoch 83, training loss: 1.13066876, training accuracy: 49.1175%, validation loss: 1.14369094, validation accuracy: 48.55%\n",
      "Epoch 84, training loss: 1.13071823, training accuracy: 49.2525%, validation loss: 1.14447415, validation accuracy: 48.86%\n",
      "Epoch 85, training loss: 1.13075495, training accuracy: 49.18875%, validation loss: 1.14305580, validation accuracy: 48.785000000000004%\n",
      "Epoch 86, training loss: 1.13081050, training accuracy: 49.198750000000004%, validation loss: 1.14274406, validation accuracy: 48.615%\n",
      "Epoch 87, training loss: 1.13080573, training accuracy: 49.198750000000004%, validation loss: 1.14395595, validation accuracy: 48.675000000000004%\n",
      "Epoch 88, training loss: 1.13075960, training accuracy: 49.19375%, validation loss: 1.14384151, validation accuracy: 48.805%\n",
      "Epoch 89, training loss: 1.13062847, training accuracy: 49.22875%, validation loss: 1.14285076, validation accuracy: 48.675000000000004%\n",
      "Epoch 90, training loss: 1.13096523, training accuracy: 49.2475%, validation loss: 1.14334416, validation accuracy: 48.835%\n",
      "Epoch 91, training loss: 1.13089561, training accuracy: 49.145%, validation loss: 1.14439571, validation accuracy: 48.695%\n",
      "Epoch 92, training loss: 1.13076568, training accuracy: 49.19%, validation loss: 1.14359272, validation accuracy: 48.63%\n",
      "Epoch 93, training loss: 1.13069105, training accuracy: 49.08625%, validation loss: 1.14280212, validation accuracy: 48.695%\n",
      "Epoch 94, training loss: 1.13056505, training accuracy: 49.2125%, validation loss: 1.14312708, validation accuracy: 48.665000000000006%\n",
      "Epoch 95, training loss: 1.13080347, training accuracy: 49.18125%, validation loss: 1.14232242, validation accuracy: 48.72%\n",
      "Epoch 96, training loss: 1.13086236, training accuracy: 49.152499999999996%, validation loss: 1.14358497, validation accuracy: 48.655%\n",
      "Epoch 97, training loss: 1.13057208, training accuracy: 49.120000000000005%, validation loss: 1.14276183, validation accuracy: 48.754999999999995%\n",
      "Epoch 98, training loss: 1.13058686, training accuracy: 49.2325%, validation loss: 1.14270163, validation accuracy: 48.77%\n",
      "Epoch 99, training loss: 1.13042521, training accuracy: 49.28875%, validation loss: 1.14232087, validation accuracy: 48.809999999999995%\n",
      "Epoch 100, training loss: 1.13059580, training accuracy: 49.27125%, validation loss: 1.14394426, validation accuracy: 48.730000000000004%\n",
      "Epoch 101, training loss: 1.13051152, training accuracy: 49.25%, validation loss: 1.14233291, validation accuracy: 48.745%\n",
      "Epoch 102, training loss: 1.13050222, training accuracy: 49.24625%, validation loss: 1.14350820, validation accuracy: 48.75%\n",
      "Epoch 103, training loss: 1.13059020, training accuracy: 49.285000000000004%, validation loss: 1.14336443, validation accuracy: 48.585%\n",
      "Epoch 104, training loss: 1.13060164, training accuracy: 49.176249999999996%, validation loss: 1.14424527, validation accuracy: 48.745%\n",
      "Epoch 105, training loss: 1.13065457, training accuracy: 49.18%, validation loss: 1.14344704, validation accuracy: 48.675000000000004%\n",
      "Epoch 106, training loss: 1.13052487, training accuracy: 49.21875%, validation loss: 1.14521837, validation accuracy: 48.875%\n",
      "Epoch 107, training loss: 1.13051176, training accuracy: 49.152499999999996%, validation loss: 1.14342725, validation accuracy: 48.71%\n",
      "Epoch 108, training loss: 1.13054037, training accuracy: 49.22375%, validation loss: 1.14252162, validation accuracy: 48.75%\n",
      "Epoch 109, training loss: 1.13061416, training accuracy: 49.21125%, validation loss: 1.14315474, validation accuracy: 48.525%\n",
      "Epoch 110, training loss: 1.13056898, training accuracy: 49.21%, validation loss: 1.14338386, validation accuracy: 48.605%\n",
      "Epoch 111, training loss: 1.13036585, training accuracy: 49.2825%, validation loss: 1.14274120, validation accuracy: 48.65%\n",
      "Epoch 112, training loss: 1.13044596, training accuracy: 49.28375%, validation loss: 1.14304280, validation accuracy: 48.53%\n",
      "Epoch 113, training loss: 1.13054943, training accuracy: 49.14875%, validation loss: 1.14362633, validation accuracy: 48.745%\n",
      "Epoch 114, training loss: 1.13037908, training accuracy: 49.26%, validation loss: 1.14238513, validation accuracy: 48.635%\n",
      "Epoch 115, training loss: 1.13040960, training accuracy: 49.235%, validation loss: 1.14324248, validation accuracy: 48.74%\n",
      "Epoch 116, training loss: 1.13040435, training accuracy: 49.198750000000004%, validation loss: 1.14681578, validation accuracy: 48.67%\n",
      "Epoch 117, training loss: 1.13029814, training accuracy: 49.23375%, validation loss: 1.14349890, validation accuracy: 48.715%\n",
      "Epoch 118, training loss: 1.13055444, training accuracy: 49.207499999999996%, validation loss: 1.14267969, validation accuracy: 48.765%\n",
      "Epoch 119, training loss: 1.13030326, training accuracy: 49.22125%, validation loss: 1.14372075, validation accuracy: 48.67%\n",
      "Epoch 120, training loss: 1.13050544, training accuracy: 49.21875%, validation loss: 1.14347923, validation accuracy: 48.67%\n",
      "Epoch 121, training loss: 1.13042808, training accuracy: 49.28375%, validation loss: 1.14226532, validation accuracy: 48.66%\n",
      "Epoch 122, training loss: 1.13038588, training accuracy: 49.214999999999996%, validation loss: 1.14373279, validation accuracy: 48.725%\n",
      "Epoch 123, training loss: 1.13025832, training accuracy: 49.2675%, validation loss: 1.14321160, validation accuracy: 48.485%\n",
      "Epoch 124, training loss: 1.13044596, training accuracy: 49.198750000000004%, validation loss: 1.14280152, validation accuracy: 48.69%\n",
      "Epoch 125, training loss: 1.13007379, training accuracy: 49.21875%, validation loss: 1.14237320, validation accuracy: 48.775%\n",
      "Epoch 126, training loss: 1.13022208, training accuracy: 49.25875%, validation loss: 1.14368069, validation accuracy: 48.699999999999996%\n",
      "Epoch 127, training loss: 1.13021338, training accuracy: 49.1575%, validation loss: 1.14224887, validation accuracy: 48.765%\n",
      "Epoch 128, training loss: 1.13024080, training accuracy: 49.24875%, validation loss: 1.14237297, validation accuracy: 48.53%\n",
      "Epoch 129, training loss: 1.13021362, training accuracy: 49.155%, validation loss: 1.14451885, validation accuracy: 48.71%\n",
      "Epoch 130, training loss: 1.13033521, training accuracy: 49.165%, validation loss: 1.14443219, validation accuracy: 48.565000000000005%\n",
      "Epoch 131, training loss: 1.13030565, training accuracy: 49.22625%, validation loss: 1.14378262, validation accuracy: 48.67%\n",
      "Epoch 132, training loss: 1.13050675, training accuracy: 49.28125%, validation loss: 1.14377439, validation accuracy: 48.67%\n",
      "Epoch 133, training loss: 1.13036120, training accuracy: 49.17125%, validation loss: 1.14253390, validation accuracy: 48.71%\n",
      "Epoch 134, training loss: 1.13009727, training accuracy: 49.24875%, validation loss: 1.14722490, validation accuracy: 48.620000000000005%\n",
      "Epoch 135, training loss: 1.13044310, training accuracy: 49.26%, validation loss: 1.14228356, validation accuracy: 48.65%\n",
      "Epoch 136, training loss: 1.13019598, training accuracy: 49.138749999999995%, validation loss: 1.14306152, validation accuracy: 48.63%\n",
      "Epoch 137, training loss: 1.13022494, training accuracy: 49.17125%, validation loss: 1.14265895, validation accuracy: 48.67%\n",
      "Epoch 138, training loss: 1.12998629, training accuracy: 49.25875%, validation loss: 1.14319122, validation accuracy: 48.76%\n",
      "Epoch 139, training loss: 1.13031530, training accuracy: 49.25875%, validation loss: 1.14267254, validation accuracy: 48.69%\n",
      "Epoch 140, training loss: 1.13018775, training accuracy: 49.21375%, validation loss: 1.14321065, validation accuracy: 48.75%\n",
      "Epoch 141, training loss: 1.13035679, training accuracy: 49.138749999999995%, validation loss: 1.14254212, validation accuracy: 48.78%\n",
      "Epoch 142, training loss: 1.13022077, training accuracy: 49.198750000000004%, validation loss: 1.14270151, validation accuracy: 48.765%\n",
      "Epoch 143, training loss: 1.13010049, training accuracy: 49.28875%, validation loss: 1.14354646, validation accuracy: 48.730000000000004%\n",
      "Epoch 144, training loss: 1.13003850, training accuracy: 49.2425%, validation loss: 1.14329469, validation accuracy: 48.725%\n",
      "Epoch 145, training loss: 1.13004506, training accuracy: 49.24%, validation loss: 1.14377403, validation accuracy: 48.79%\n",
      "Epoch 146, training loss: 1.13015199, training accuracy: 49.26%, validation loss: 1.14416683, validation accuracy: 48.825%\n",
      "Epoch 147, training loss: 1.12993360, training accuracy: 49.26375%, validation loss: 1.14315581, validation accuracy: 48.725%\n",
      "Epoch 148, training loss: 1.13027775, training accuracy: 49.2275%, validation loss: 1.14557779, validation accuracy: 48.59%\n",
      "Epoch 149, training loss: 1.13007271, training accuracy: 49.2375%, validation loss: 1.14270020, validation accuracy: 48.855%\n",
      "Epoch 150, training loss: 1.13009548, training accuracy: 49.27125%, validation loss: 1.14354122, validation accuracy: 48.805%\n",
      "Epoch 151, training loss: 1.13011909, training accuracy: 49.33%, validation loss: 1.14283383, validation accuracy: 48.655%\n",
      "Epoch 152, training loss: 1.13021040, training accuracy: 49.29125%, validation loss: 1.14327037, validation accuracy: 48.625%\n",
      "Epoch 153, training loss: 1.13023114, training accuracy: 49.18%, validation loss: 1.14324343, validation accuracy: 48.69%\n",
      "Epoch 154, training loss: 1.13004613, training accuracy: 49.1925%, validation loss: 1.14385116, validation accuracy: 48.67%\n",
      "Epoch 155, training loss: 1.13017786, training accuracy: 49.30125%, validation loss: 1.14237416, validation accuracy: 48.66%\n",
      "Epoch 156, training loss: 1.12999129, training accuracy: 49.21%, validation loss: 1.14411414, validation accuracy: 48.735%\n",
      "Epoch 157, training loss: 1.13022625, training accuracy: 49.26375%, validation loss: 1.14323664, validation accuracy: 48.585%\n",
      "Epoch 158, training loss: 1.12995625, training accuracy: 49.2925%, validation loss: 1.14373100, validation accuracy: 48.695%\n",
      "Epoch 159, training loss: 1.12982404, training accuracy: 49.29125%, validation loss: 1.14383805, validation accuracy: 48.655%\n",
      "Epoch 160, training loss: 1.13003278, training accuracy: 49.293749999999996%, validation loss: 1.14358449, validation accuracy: 48.72%\n",
      "Epoch 161, training loss: 1.12999594, training accuracy: 49.1975%, validation loss: 1.14229739, validation accuracy: 48.665000000000006%\n",
      "Epoch 162, training loss: 1.12985873, training accuracy: 49.24125%, validation loss: 1.14287245, validation accuracy: 48.71%\n",
      "Epoch 163, training loss: 1.12994230, training accuracy: 49.2375%, validation loss: 1.14673805, validation accuracy: 48.71%\n",
      "Epoch 164, training loss: 1.13008523, training accuracy: 49.30625%, validation loss: 1.14410293, validation accuracy: 48.57%\n",
      "Epoch 165, training loss: 1.12996364, training accuracy: 49.245%, validation loss: 1.14307451, validation accuracy: 48.71%\n",
      "Epoch 166, training loss: 1.12988532, training accuracy: 49.2875%, validation loss: 1.14405048, validation accuracy: 48.69%\n",
      "Epoch 167, training loss: 1.12979865, training accuracy: 49.261250000000004%, validation loss: 1.14396369, validation accuracy: 48.705%\n",
      "Epoch 168, training loss: 1.12989283, training accuracy: 49.298750000000005%, validation loss: 1.14281297, validation accuracy: 48.504999999999995%\n",
      "Epoch 169, training loss: 1.13002610, training accuracy: 49.21125%, validation loss: 1.14410281, validation accuracy: 48.64%\n",
      "Epoch 170, training loss: 1.12993002, training accuracy: 49.25%, validation loss: 1.14320874, validation accuracy: 48.735%\n",
      "Epoch 171, training loss: 1.12983346, training accuracy: 49.24%, validation loss: 1.14431536, validation accuracy: 48.870000000000005%\n",
      "Epoch 172, training loss: 1.13009846, training accuracy: 49.28375%, validation loss: 1.14511740, validation accuracy: 48.615%\n",
      "Epoch 173, training loss: 1.12981939, training accuracy: 49.16625%, validation loss: 1.14356828, validation accuracy: 48.67%\n",
      "Epoch 174, training loss: 1.12994480, training accuracy: 49.230000000000004%, validation loss: 1.14222240, validation accuracy: 48.699999999999996%\n",
      "Epoch 175, training loss: 1.12997162, training accuracy: 49.3025%, validation loss: 1.14406216, validation accuracy: 48.575%\n",
      "Epoch 176, training loss: 1.12979209, training accuracy: 49.29125%, validation loss: 1.14406848, validation accuracy: 48.63%\n",
      "Epoch 177, training loss: 1.12987125, training accuracy: 49.2525%, validation loss: 1.14367688, validation accuracy: 48.59%\n",
      "Epoch 178, training loss: 1.12978804, training accuracy: 49.21375%, validation loss: 1.14528787, validation accuracy: 48.79%\n",
      "Epoch 179, training loss: 1.12998736, training accuracy: 49.23625%, validation loss: 1.14396167, validation accuracy: 48.55%\n",
      "Epoch 180, training loss: 1.12994790, training accuracy: 49.2475%, validation loss: 1.14507377, validation accuracy: 48.805%\n",
      "Epoch 181, training loss: 1.12983835, training accuracy: 49.16375%, validation loss: 1.14295578, validation accuracy: 48.9%\n",
      "Epoch 182, training loss: 1.12983978, training accuracy: 49.262499999999996%, validation loss: 1.14256740, validation accuracy: 48.805%\n",
      "Epoch 183, training loss: 1.12994778, training accuracy: 49.275000000000006%, validation loss: 1.14428163, validation accuracy: 48.67%\n",
      "Epoch 184, training loss: 1.12990797, training accuracy: 49.28%, validation loss: 1.14453745, validation accuracy: 48.68%\n",
      "Epoch 185, training loss: 1.12987554, training accuracy: 49.3%, validation loss: 1.14354098, validation accuracy: 48.72%\n",
      "Epoch 186, training loss: 1.12991333, training accuracy: 49.24125%, validation loss: 1.14264154, validation accuracy: 48.805%\n",
      "Epoch 187, training loss: 1.12981558, training accuracy: 49.198750000000004%, validation loss: 1.14391291, validation accuracy: 48.730000000000004%\n",
      "Epoch 188, training loss: 1.12975967, training accuracy: 49.39625%, validation loss: 1.14466834, validation accuracy: 48.57%\n",
      "Epoch 189, training loss: 1.13007271, training accuracy: 49.33125%, validation loss: 1.14381528, validation accuracy: 48.46%\n",
      "Epoch 190, training loss: 1.12955236, training accuracy: 49.24%, validation loss: 1.14723861, validation accuracy: 48.375%\n",
      "Epoch 191, training loss: 1.12987387, training accuracy: 49.29%, validation loss: 1.14253390, validation accuracy: 48.68%\n",
      "Epoch 192, training loss: 1.12984586, training accuracy: 49.26625%, validation loss: 1.14413810, validation accuracy: 48.555%\n",
      "Epoch 193, training loss: 1.12972248, training accuracy: 49.30625%, validation loss: 1.14556360, validation accuracy: 48.58%\n",
      "Epoch 194, training loss: 1.12953115, training accuracy: 49.31875%, validation loss: 1.14444840, validation accuracy: 48.55%\n",
      "Epoch 195, training loss: 1.12981284, training accuracy: 49.316250000000004%, validation loss: 1.14308476, validation accuracy: 48.64%\n",
      "Epoch 196, training loss: 1.12979710, training accuracy: 49.24375%, validation loss: 1.14439356, validation accuracy: 48.805%\n",
      "Epoch 197, training loss: 1.12958264, training accuracy: 49.27375%, validation loss: 1.14302671, validation accuracy: 48.6%\n",
      "Epoch 198, training loss: 1.12962699, training accuracy: 49.254999999999995%, validation loss: 1.14424479, validation accuracy: 48.575%\n",
      "Epoch 199, training loss: 1.12958872, training accuracy: 49.245%, validation loss: 1.14602005, validation accuracy: 48.535000000000004%\n",
      "Epoch 200, training loss: 1.12972677, training accuracy: 49.30375%, validation loss: 1.14454067, validation accuracy: 48.65%\n",
      "Epoch 201, training loss: 1.12970078, training accuracy: 49.231249999999996%, validation loss: 1.14350033, validation accuracy: 48.72%\n",
      "Epoch 202, training loss: 1.12976861, training accuracy: 49.205%, validation loss: 1.14333546, validation accuracy: 48.64%\n",
      "Epoch 203, training loss: 1.12971115, training accuracy: 49.2375%, validation loss: 1.14319980, validation accuracy: 48.8%\n",
      "Epoch 204, training loss: 1.12964308, training accuracy: 49.26375%, validation loss: 1.14327133, validation accuracy: 48.695%\n",
      "Epoch 205, training loss: 1.12953246, training accuracy: 49.30375%, validation loss: 1.14419198, validation accuracy: 48.735%\n",
      "Epoch 206, training loss: 1.12965953, training accuracy: 49.27875%, validation loss: 1.14460683, validation accuracy: 48.805%\n",
      "Epoch 207, training loss: 1.12965798, training accuracy: 49.22875%, validation loss: 1.14324176, validation accuracy: 48.68%\n",
      "Epoch 208, training loss: 1.12966001, training accuracy: 49.27875%, validation loss: 1.14542079, validation accuracy: 48.375%\n",
      "Epoch 209, training loss: 1.12962937, training accuracy: 49.2875%, validation loss: 1.14322567, validation accuracy: 48.644999999999996%\n",
      "Epoch 210, training loss: 1.12961352, training accuracy: 49.2825%, validation loss: 1.14351547, validation accuracy: 48.79%\n",
      "Epoch 211, training loss: 1.12957656, training accuracy: 49.23625%, validation loss: 1.14600825, validation accuracy: 48.635%\n",
      "Epoch 212, training loss: 1.12960494, training accuracy: 49.2975%, validation loss: 1.14423335, validation accuracy: 48.71%\n",
      "Epoch 213, training loss: 1.12956929, training accuracy: 49.27375%, validation loss: 1.14466834, validation accuracy: 48.61%\n",
      "Epoch 214, training loss: 1.12949705, training accuracy: 49.3475%, validation loss: 1.14451528, validation accuracy: 48.699999999999996%\n",
      "Epoch 215, training loss: 1.12958467, training accuracy: 49.21375%, validation loss: 1.14371979, validation accuracy: 48.575%\n",
      "Epoch 216, training loss: 1.12970436, training accuracy: 49.21625%, validation loss: 1.14422286, validation accuracy: 48.63%\n",
      "Epoch 217, training loss: 1.12958646, training accuracy: 49.33125%, validation loss: 1.14367521, validation accuracy: 48.58%\n",
      "Epoch 218, training loss: 1.12958872, training accuracy: 49.261250000000004%, validation loss: 1.14363611, validation accuracy: 48.735%\n",
      "Epoch 219, training loss: 1.12956119, training accuracy: 49.315%, validation loss: 1.14404237, validation accuracy: 48.63%\n",
      "Epoch 220, training loss: 1.12957585, training accuracy: 49.33%, validation loss: 1.14453530, validation accuracy: 48.685%\n",
      "Epoch 221, training loss: 1.12953448, training accuracy: 49.24875%, validation loss: 1.14385223, validation accuracy: 48.595%\n",
      "Epoch 222, training loss: 1.12958884, training accuracy: 49.2875%, validation loss: 1.14375985, validation accuracy: 48.805%\n",
      "Epoch 223, training loss: 1.12945557, training accuracy: 49.30125%, validation loss: 1.14576280, validation accuracy: 48.355%\n",
      "Epoch 224, training loss: 1.12958384, training accuracy: 49.32375%, validation loss: 1.14322007, validation accuracy: 48.705%\n",
      "Epoch 225, training loss: 1.12954664, training accuracy: 49.26875%, validation loss: 1.14414108, validation accuracy: 48.58%\n",
      "Epoch 226, training loss: 1.12939072, training accuracy: 49.317499999999995%, validation loss: 1.14352965, validation accuracy: 48.815%\n",
      "Epoch 227, training loss: 1.12949431, training accuracy: 49.2775%, validation loss: 1.14335525, validation accuracy: 48.835%\n",
      "Epoch 228, training loss: 1.12961245, training accuracy: 49.253750000000004%, validation loss: 1.14562333, validation accuracy: 48.775%\n",
      "Epoch 229, training loss: 1.12938726, training accuracy: 49.24625%, validation loss: 1.14431310, validation accuracy: 48.68%\n",
      "Epoch 230, training loss: 1.12944627, training accuracy: 49.25875%, validation loss: 1.14464903, validation accuracy: 48.745%\n",
      "Epoch 231, training loss: 1.12939107, training accuracy: 49.32375%, validation loss: 1.14431059, validation accuracy: 48.68%\n",
      "Epoch 232, training loss: 1.12936342, training accuracy: 49.35%, validation loss: 1.14376020, validation accuracy: 48.615%\n",
      "Epoch 233, training loss: 1.12948823, training accuracy: 49.33%, validation loss: 1.14269125, validation accuracy: 48.655%\n",
      "Epoch 234, training loss: 1.12933588, training accuracy: 49.3025%, validation loss: 1.14386642, validation accuracy: 48.67%\n",
      "Epoch 235, training loss: 1.12944329, training accuracy: 49.262499999999996%, validation loss: 1.14326298, validation accuracy: 48.555%\n",
      "Epoch 236, training loss: 1.12939119, training accuracy: 49.33125%, validation loss: 1.14381671, validation accuracy: 48.6%\n",
      "Epoch 237, training loss: 1.12954116, training accuracy: 49.3425%, validation loss: 1.14425147, validation accuracy: 48.66%\n",
      "Epoch 238, training loss: 1.12942624, training accuracy: 49.207499999999996%, validation loss: 1.14456630, validation accuracy: 48.72%\n",
      "Epoch 239, training loss: 1.12939155, training accuracy: 49.305%, validation loss: 1.14268816, validation accuracy: 48.730000000000004%\n",
      "Epoch 240, training loss: 1.12932134, training accuracy: 49.21%, validation loss: 1.14508235, validation accuracy: 48.57%\n",
      "Epoch 241, training loss: 1.12941504, training accuracy: 49.26375%, validation loss: 1.14607716, validation accuracy: 48.635%\n",
      "Epoch 242, training loss: 1.12933648, training accuracy: 49.309999999999995%, validation loss: 1.14468241, validation accuracy: 48.47%\n",
      "Epoch 243, training loss: 1.12925851, training accuracy: 49.25875%, validation loss: 1.14408386, validation accuracy: 48.64%\n",
      "Epoch 244, training loss: 1.12934244, training accuracy: 49.32%, validation loss: 1.14364648, validation accuracy: 48.6%\n",
      "Epoch 245, training loss: 1.12917399, training accuracy: 49.286249999999995%, validation loss: 1.14441752, validation accuracy: 48.59%\n",
      "Epoch 246, training loss: 1.12946713, training accuracy: 49.18625%, validation loss: 1.14359021, validation accuracy: 48.695%\n",
      "Epoch 247, training loss: 1.12934077, training accuracy: 49.28%, validation loss: 1.14382219, validation accuracy: 48.705%\n",
      "Epoch 248, training loss: 1.12938583, training accuracy: 49.29%, validation loss: 1.14311934, validation accuracy: 48.705%\n",
      "Epoch 249, training loss: 1.12937534, training accuracy: 49.22375%, validation loss: 1.14416623, validation accuracy: 48.699999999999996%\n",
      "Epoch 250, training loss: 1.12916088, training accuracy: 49.235%, validation loss: 1.14515245, validation accuracy: 48.715%\n",
      "Epoch 251, training loss: 1.12917817, training accuracy: 49.28375%, validation loss: 1.14336228, validation accuracy: 48.72%\n",
      "Epoch 252, training loss: 1.12942934, training accuracy: 49.2725%, validation loss: 1.14477408, validation accuracy: 48.65%\n",
      "Epoch 253, training loss: 1.12938702, training accuracy: 49.27%, validation loss: 1.14318299, validation accuracy: 48.809999999999995%\n",
      "Epoch 254, training loss: 1.12927997, training accuracy: 49.285000000000004%, validation loss: 1.14420593, validation accuracy: 48.795%\n",
      "Epoch 255, training loss: 1.12931919, training accuracy: 49.295%, validation loss: 1.14380062, validation accuracy: 48.635%\n",
      "Epoch 256, training loss: 1.12913287, training accuracy: 49.395%, validation loss: 1.14428091, validation accuracy: 48.75%\n",
      "Epoch 257, training loss: 1.12938488, training accuracy: 49.286249999999995%, validation loss: 1.14464939, validation accuracy: 48.72%\n",
      "Epoch 258, training loss: 1.12913764, training accuracy: 49.33875%, validation loss: 1.14375210, validation accuracy: 48.58%\n",
      "Epoch 259, training loss: 1.12931859, training accuracy: 49.2675%, validation loss: 1.14498103, validation accuracy: 48.71%\n",
      "Epoch 260, training loss: 1.12908137, training accuracy: 49.31375%, validation loss: 1.14489996, validation accuracy: 48.55%\n",
      "Epoch 261, training loss: 1.12928879, training accuracy: 49.298750000000005%, validation loss: 1.14435840, validation accuracy: 48.57%\n",
      "Epoch 262, training loss: 1.12916577, training accuracy: 49.316250000000004%, validation loss: 1.14429188, validation accuracy: 48.6%\n",
      "Epoch 263, training loss: 1.12914085, training accuracy: 49.2575%, validation loss: 1.14354122, validation accuracy: 48.77%\n",
      "Epoch 264, training loss: 1.12911952, training accuracy: 49.35875%, validation loss: 1.14381111, validation accuracy: 48.605%\n",
      "Epoch 265, training loss: 1.12918806, training accuracy: 49.27875%, validation loss: 1.14374697, validation accuracy: 48.705%\n",
      "Epoch 266, training loss: 1.12934804, training accuracy: 49.27875%, validation loss: 1.14439964, validation accuracy: 48.805%\n",
      "Epoch 267, training loss: 1.12915277, training accuracy: 49.285000000000004%, validation loss: 1.14391053, validation accuracy: 48.65%\n",
      "Epoch 268, training loss: 1.12915409, training accuracy: 49.41%, validation loss: 1.14644182, validation accuracy: 48.665000000000006%\n",
      "Epoch 269, training loss: 1.12932777, training accuracy: 49.30125%, validation loss: 1.14373100, validation accuracy: 48.575%\n",
      "Epoch 270, training loss: 1.12932575, training accuracy: 49.262499999999996%, validation loss: 1.14406121, validation accuracy: 48.64%\n",
      "Epoch 271, training loss: 1.12912858, training accuracy: 49.24625%, validation loss: 1.14375484, validation accuracy: 48.8%\n",
      "Epoch 272, training loss: 1.12901664, training accuracy: 49.3025%, validation loss: 1.14365005, validation accuracy: 48.68%\n",
      "Epoch 273, training loss: 1.12919533, training accuracy: 49.3%, validation loss: 1.14602542, validation accuracy: 48.620000000000005%\n",
      "Epoch 274, training loss: 1.12907338, training accuracy: 49.37625%, validation loss: 1.14383852, validation accuracy: 48.835%\n",
      "Epoch 275, training loss: 1.12910295, training accuracy: 49.32%, validation loss: 1.14300215, validation accuracy: 48.635%\n",
      "Epoch 276, training loss: 1.12918806, training accuracy: 49.2725%, validation loss: 1.14551842, validation accuracy: 48.385%\n",
      "Epoch 277, training loss: 1.12918961, training accuracy: 49.32%, validation loss: 1.14435005, validation accuracy: 48.68%\n",
      "Epoch 278, training loss: 1.12896693, training accuracy: 49.27875%, validation loss: 1.14316094, validation accuracy: 48.64%\n",
      "Epoch 279, training loss: 1.12899125, training accuracy: 49.21875%, validation loss: 1.14437485, validation accuracy: 48.625%\n",
      "Epoch 280, training loss: 1.12915778, training accuracy: 49.27125%, validation loss: 1.14547646, validation accuracy: 48.545%\n",
      "Epoch 281, training loss: 1.12898052, training accuracy: 49.18%, validation loss: 1.14355111, validation accuracy: 48.620000000000005%\n",
      "Epoch 282, training loss: 1.12916934, training accuracy: 49.25875%, validation loss: 1.14378595, validation accuracy: 48.685%\n",
      "Epoch 283, training loss: 1.12899947, training accuracy: 49.28%, validation loss: 1.14587951, validation accuracy: 48.620000000000005%\n",
      "Epoch 284, training loss: 1.12909877, training accuracy: 49.31875%, validation loss: 1.14442992, validation accuracy: 48.54%\n",
      "Epoch 285, training loss: 1.12905669, training accuracy: 49.355%, validation loss: 1.14497352, validation accuracy: 48.71%\n",
      "Epoch 286, training loss: 1.12907350, training accuracy: 49.32375%, validation loss: 1.14487696, validation accuracy: 48.644999999999996%\n",
      "Epoch 287, training loss: 1.12901986, training accuracy: 49.262499999999996%, validation loss: 1.14654160, validation accuracy: 48.495%\n",
      "Epoch 288, training loss: 1.12900352, training accuracy: 49.37375%, validation loss: 1.14366424, validation accuracy: 48.58%\n",
      "Epoch 289, training loss: 1.12897003, training accuracy: 49.31125%, validation loss: 1.14496922, validation accuracy: 48.585%\n",
      "Epoch 290, training loss: 1.12910366, training accuracy: 49.3025%, validation loss: 1.14363682, validation accuracy: 48.695%\n",
      "Epoch 291, training loss: 1.12908959, training accuracy: 49.3075%, validation loss: 1.14486980, validation accuracy: 48.425000000000004%\n",
      "Epoch 292, training loss: 1.12898684, training accuracy: 49.33%, validation loss: 1.14504504, validation accuracy: 48.809999999999995%\n",
      "Epoch 293, training loss: 1.12908030, training accuracy: 49.2825%, validation loss: 1.14508975, validation accuracy: 48.63%\n",
      "Epoch 294, training loss: 1.12899077, training accuracy: 49.34%, validation loss: 1.14356077, validation accuracy: 48.635%\n",
      "Epoch 295, training loss: 1.12887573, training accuracy: 49.26%, validation loss: 1.14484107, validation accuracy: 48.68%\n",
      "Epoch 296, training loss: 1.12878335, training accuracy: 49.3075%, validation loss: 1.14431787, validation accuracy: 48.735%\n",
      "Epoch 297, training loss: 1.12914324, training accuracy: 49.3325%, validation loss: 1.14492452, validation accuracy: 48.785000000000004%\n",
      "Epoch 298, training loss: 1.12894809, training accuracy: 49.31125%, validation loss: 1.14418340, validation accuracy: 48.615%\n",
      "Epoch 299, training loss: 1.12915504, training accuracy: 49.3425%, validation loss: 1.14364862, validation accuracy: 48.635%\n",
      "Epoch 300, training loss: 1.12904370, training accuracy: 49.3%, validation loss: 1.14333904, validation accuracy: 48.75%\n",
      "Epoch 301, training loss: 1.12895572, training accuracy: 49.25%, validation loss: 1.14387071, validation accuracy: 48.64%\n",
      "Epoch 302, training loss: 1.12898028, training accuracy: 49.3425%, validation loss: 1.14448655, validation accuracy: 48.85%\n",
      "Epoch 303, training loss: 1.12909365, training accuracy: 49.265%, validation loss: 1.14503896, validation accuracy: 48.765%\n",
      "Epoch 304, training loss: 1.12890518, training accuracy: 49.36375%, validation loss: 1.14450443, validation accuracy: 48.725%\n",
      "Epoch 305, training loss: 1.12905562, training accuracy: 49.26375%, validation loss: 1.14428210, validation accuracy: 48.52%\n",
      "Epoch 306, training loss: 1.12902260, training accuracy: 49.265%, validation loss: 1.14407468, validation accuracy: 48.699999999999996%\n",
      "Epoch 307, training loss: 1.12893367, training accuracy: 49.3475%, validation loss: 1.14433897, validation accuracy: 48.754999999999995%\n",
      "Epoch 308, training loss: 1.12884283, training accuracy: 49.3275%, validation loss: 1.14324033, validation accuracy: 48.72%\n",
      "Epoch 309, training loss: 1.12892628, training accuracy: 49.3325%, validation loss: 1.14390492, validation accuracy: 48.699999999999996%\n",
      "Epoch 310, training loss: 1.12900388, training accuracy: 49.1975%, validation loss: 1.14419985, validation accuracy: 48.725%\n",
      "Epoch 311, training loss: 1.12890327, training accuracy: 49.2925%, validation loss: 1.14681458, validation accuracy: 48.66%\n",
      "Epoch 312, training loss: 1.12904322, training accuracy: 49.295%, validation loss: 1.14549541, validation accuracy: 48.74%\n",
      "Epoch 313, training loss: 1.12879241, training accuracy: 49.30125%, validation loss: 1.14380121, validation accuracy: 48.725%\n",
      "Epoch 314, training loss: 1.12872291, training accuracy: 49.35625%, validation loss: 1.14496779, validation accuracy: 48.555%\n",
      "Epoch 315, training loss: 1.12890470, training accuracy: 49.28125%, validation loss: 1.14398217, validation accuracy: 48.66%\n",
      "Epoch 316, training loss: 1.12883794, training accuracy: 49.24625%, validation loss: 1.14659667, validation accuracy: 48.485%\n",
      "Epoch 317, training loss: 1.12913013, training accuracy: 49.309999999999995%, validation loss: 1.14368391, validation accuracy: 48.67%\n",
      "Epoch 318, training loss: 1.12888992, training accuracy: 49.295%, validation loss: 1.14406860, validation accuracy: 48.6%\n",
      "Epoch 319, training loss: 1.12884665, training accuracy: 49.25875%, validation loss: 1.14547753, validation accuracy: 48.655%\n",
      "Epoch 320, training loss: 1.12890041, training accuracy: 49.325%, validation loss: 1.14511585, validation accuracy: 48.525%\n",
      "Epoch 321, training loss: 1.12867069, training accuracy: 49.3275%, validation loss: 1.14530897, validation accuracy: 48.435%\n",
      "Epoch 322, training loss: 1.12903535, training accuracy: 49.225%, validation loss: 1.14480865, validation accuracy: 48.67%\n",
      "Epoch 323, training loss: 1.12874532, training accuracy: 49.3075%, validation loss: 1.14450049, validation accuracy: 48.63%\n",
      "Epoch 324, training loss: 1.12901890, training accuracy: 49.28375%, validation loss: 1.14574385, validation accuracy: 48.65%\n",
      "Epoch 325, training loss: 1.12888455, training accuracy: 49.2775%, validation loss: 1.14568698, validation accuracy: 48.78%\n",
      "Epoch 326, training loss: 1.12902963, training accuracy: 49.33875%, validation loss: 1.14503026, validation accuracy: 48.815%\n",
      "Epoch 327, training loss: 1.12900090, training accuracy: 49.26375%, validation loss: 1.14410722, validation accuracy: 48.644999999999996%\n",
      "Epoch 328, training loss: 1.12879491, training accuracy: 49.29625%, validation loss: 1.14468670, validation accuracy: 48.63%\n",
      "Epoch 329, training loss: 1.12895191, training accuracy: 49.322500000000005%, validation loss: 1.14413416, validation accuracy: 48.63%\n",
      "Epoch 330, training loss: 1.12887573, training accuracy: 49.2425%, validation loss: 1.14388239, validation accuracy: 48.78%\n",
      "Epoch 331, training loss: 1.12886751, training accuracy: 49.285000000000004%, validation loss: 1.14559650, validation accuracy: 48.5%\n",
      "Epoch 332, training loss: 1.12895989, training accuracy: 49.36875%, validation loss: 1.14466941, validation accuracy: 48.725%\n",
      "Epoch 333, training loss: 1.12870228, training accuracy: 49.286249999999995%, validation loss: 1.14428747, validation accuracy: 48.620000000000005%\n",
      "Epoch 334, training loss: 1.12885427, training accuracy: 49.325%, validation loss: 1.14424801, validation accuracy: 48.685%\n",
      "Epoch 335, training loss: 1.12880087, training accuracy: 49.35%, validation loss: 1.14384532, validation accuracy: 48.6%\n",
      "Epoch 336, training loss: 1.12881958, training accuracy: 49.2525%, validation loss: 1.14444053, validation accuracy: 48.64%\n",
      "Epoch 337, training loss: 1.12876034, training accuracy: 49.3875%, validation loss: 1.14565909, validation accuracy: 48.685%\n",
      "Epoch 338, training loss: 1.12893569, training accuracy: 49.30875%, validation loss: 1.14471149, validation accuracy: 48.5%\n",
      "Epoch 339, training loss: 1.12877369, training accuracy: 49.309999999999995%, validation loss: 1.14366603, validation accuracy: 48.675000000000004%\n",
      "Epoch 340, training loss: 1.12892032, training accuracy: 49.2%, validation loss: 1.14451897, validation accuracy: 48.745%\n",
      "Epoch 341, training loss: 1.12880099, training accuracy: 49.3125%, validation loss: 1.14416683, validation accuracy: 48.84%\n",
      "Epoch 342, training loss: 1.12876832, training accuracy: 49.293749999999996%, validation loss: 1.14385438, validation accuracy: 48.625%\n",
      "Epoch 343, training loss: 1.12874544, training accuracy: 49.286249999999995%, validation loss: 1.14536512, validation accuracy: 48.61%\n",
      "Epoch 344, training loss: 1.12887466, training accuracy: 49.3575%, validation loss: 1.14356124, validation accuracy: 48.665000000000006%\n",
      "Epoch 345, training loss: 1.12887192, training accuracy: 49.2975%, validation loss: 1.14441288, validation accuracy: 48.644999999999996%\n",
      "Epoch 346, training loss: 1.12875652, training accuracy: 49.32%, validation loss: 1.14397192, validation accuracy: 48.69%\n",
      "Epoch 347, training loss: 1.12868094, training accuracy: 49.27625%, validation loss: 1.14479089, validation accuracy: 48.58%\n",
      "Epoch 348, training loss: 1.12867951, training accuracy: 49.220000000000006%, validation loss: 1.14368963, validation accuracy: 48.665000000000006%\n",
      "Epoch 349, training loss: 1.12875354, training accuracy: 49.28875%, validation loss: 1.14412379, validation accuracy: 48.495%\n",
      "Epoch 350, training loss: 1.12880564, training accuracy: 49.31375%, validation loss: 1.14418066, validation accuracy: 48.715%\n",
      "Epoch 351, training loss: 1.12889969, training accuracy: 49.29%, validation loss: 1.14534163, validation accuracy: 48.805%\n",
      "Epoch 352, training loss: 1.12875438, training accuracy: 49.32625%, validation loss: 1.14452577, validation accuracy: 48.86%\n",
      "Epoch 353, training loss: 1.12855721, training accuracy: 49.32875%, validation loss: 1.14473772, validation accuracy: 48.68%\n",
      "Epoch 354, training loss: 1.12874234, training accuracy: 49.3075%, validation loss: 1.14328587, validation accuracy: 48.809999999999995%\n",
      "Epoch 355, training loss: 1.12877083, training accuracy: 49.29625%, validation loss: 1.14344347, validation accuracy: 48.64%\n",
      "Epoch 356, training loss: 1.12870562, training accuracy: 49.34875%, validation loss: 1.14481533, validation accuracy: 48.725%\n",
      "Epoch 357, training loss: 1.12871337, training accuracy: 49.286249999999995%, validation loss: 1.14466739, validation accuracy: 48.74%\n",
      "Epoch 358, training loss: 1.12856019, training accuracy: 49.3875%, validation loss: 1.14507246, validation accuracy: 48.345%\n",
      "Epoch 359, training loss: 1.12882316, training accuracy: 49.34%, validation loss: 1.14406931, validation accuracy: 48.655%\n",
      "Epoch 360, training loss: 1.12881196, training accuracy: 49.285000000000004%, validation loss: 1.14323819, validation accuracy: 48.625%\n",
      "Epoch 361, training loss: 1.12876344, training accuracy: 49.341249999999995%, validation loss: 1.14572036, validation accuracy: 48.725%\n",
      "Epoch 362, training loss: 1.12868309, training accuracy: 49.24375%, validation loss: 1.14463675, validation accuracy: 48.66%\n",
      "Epoch 363, training loss: 1.12868989, training accuracy: 49.275000000000006%, validation loss: 1.14427352, validation accuracy: 48.5%\n",
      "Epoch 364, training loss: 1.12867975, training accuracy: 49.32625%, validation loss: 1.14429569, validation accuracy: 48.565000000000005%\n",
      "Epoch 365, training loss: 1.12874496, training accuracy: 49.36125%, validation loss: 1.14581931, validation accuracy: 48.68%\n",
      "Epoch 366, training loss: 1.12894011, training accuracy: 49.30375%, validation loss: 1.14438570, validation accuracy: 48.555%\n",
      "Epoch 367, training loss: 1.12876022, training accuracy: 49.32%, validation loss: 1.14617574, validation accuracy: 48.620000000000005%\n",
      "Epoch 368, training loss: 1.12862253, training accuracy: 49.25%, validation loss: 1.14374638, validation accuracy: 48.635%\n",
      "Epoch 369, training loss: 1.12876332, training accuracy: 49.30125%, validation loss: 1.14450192, validation accuracy: 48.575%\n",
      "Epoch 370, training loss: 1.12880063, training accuracy: 49.25125%, validation loss: 1.14458096, validation accuracy: 48.69%\n",
      "Epoch 371, training loss: 1.12859786, training accuracy: 49.30875%, validation loss: 1.14279342, validation accuracy: 48.72%\n",
      "Epoch 372, training loss: 1.12853158, training accuracy: 49.309999999999995%, validation loss: 1.14447403, validation accuracy: 48.625%\n",
      "Epoch 373, training loss: 1.12861645, training accuracy: 49.33625%, validation loss: 1.14492500, validation accuracy: 48.65%\n",
      "Epoch 374, training loss: 1.12869322, training accuracy: 49.3275%, validation loss: 1.14558172, validation accuracy: 48.68%\n",
      "Epoch 375, training loss: 1.12859690, training accuracy: 49.293749999999996%, validation loss: 1.14361846, validation accuracy: 48.69%\n",
      "Epoch 376, training loss: 1.12861764, training accuracy: 49.3925%, validation loss: 1.14434016, validation accuracy: 48.625%\n",
      "Epoch 377, training loss: 1.12869728, training accuracy: 49.36625%, validation loss: 1.14464426, validation accuracy: 48.63%\n",
      "Epoch 378, training loss: 1.12866366, training accuracy: 49.31875%, validation loss: 1.14543414, validation accuracy: 48.53%\n",
      "Epoch 379, training loss: 1.12870932, training accuracy: 49.39375%, validation loss: 1.14539921, validation accuracy: 48.72%\n",
      "Epoch 380, training loss: 1.12869787, training accuracy: 49.38125%, validation loss: 1.14484668, validation accuracy: 48.805%\n",
      "Epoch 381, training loss: 1.12881565, training accuracy: 49.37375%, validation loss: 1.14539337, validation accuracy: 48.6%\n",
      "Epoch 382, training loss: 1.12858689, training accuracy: 49.325%, validation loss: 1.14578593, validation accuracy: 48.699999999999996%\n",
      "Epoch 383, training loss: 1.12869203, training accuracy: 49.316250000000004%, validation loss: 1.14420307, validation accuracy: 48.83%\n",
      "Epoch 384, training loss: 1.12846732, training accuracy: 49.293749999999996%, validation loss: 1.14462626, validation accuracy: 48.74%\n",
      "Epoch 385, training loss: 1.12866044, training accuracy: 49.2775%, validation loss: 1.14644980, validation accuracy: 48.83%\n",
      "Epoch 386, training loss: 1.12868404, training accuracy: 49.31375%, validation loss: 1.14441979, validation accuracy: 48.675000000000004%\n",
      "Epoch 387, training loss: 1.12850225, training accuracy: 49.37375%, validation loss: 1.14533079, validation accuracy: 48.620000000000005%\n",
      "Epoch 388, training loss: 1.12852609, training accuracy: 49.3375%, validation loss: 1.14411092, validation accuracy: 48.655%\n",
      "Epoch 389, training loss: 1.12860405, training accuracy: 49.2675%, validation loss: 1.14294684, validation accuracy: 48.66%\n",
      "Epoch 390, training loss: 1.12866020, training accuracy: 49.2675%, validation loss: 1.14361882, validation accuracy: 48.695%\n",
      "Epoch 391, training loss: 1.12852848, training accuracy: 49.3625%, validation loss: 1.14503193, validation accuracy: 48.559999999999995%\n",
      "Epoch 392, training loss: 1.12877715, training accuracy: 49.30375%, validation loss: 1.14455283, validation accuracy: 48.595%\n",
      "Epoch 393, training loss: 1.12862134, training accuracy: 49.27625%, validation loss: 1.14451730, validation accuracy: 48.615%\n",
      "Epoch 394, training loss: 1.12861264, training accuracy: 49.28375%, validation loss: 1.14533186, validation accuracy: 48.66%\n",
      "Epoch 395, training loss: 1.12853491, training accuracy: 49.317499999999995%, validation loss: 1.14605081, validation accuracy: 48.52%\n",
      "Epoch 396, training loss: 1.12857985, training accuracy: 49.2825%, validation loss: 1.14472854, validation accuracy: 48.485%\n",
      "Epoch 397, training loss: 1.12865055, training accuracy: 49.30375%, validation loss: 1.14616561, validation accuracy: 48.76%\n",
      "Epoch 398, training loss: 1.12846351, training accuracy: 49.401250000000005%, validation loss: 1.14396954, validation accuracy: 48.61%\n",
      "Epoch 399, training loss: 1.12865913, training accuracy: 49.27375%, validation loss: 1.14507723, validation accuracy: 48.595%\n",
      "Epoch 400, training loss: 1.12854683, training accuracy: 49.30625%, validation loss: 1.14454067, validation accuracy: 48.64%\n",
      "Epoch 401, training loss: 1.12861860, training accuracy: 49.33875%, validation loss: 1.14430654, validation accuracy: 48.715%\n",
      "Epoch 402, training loss: 1.12840962, training accuracy: 49.375%, validation loss: 1.14463520, validation accuracy: 48.655%\n",
      "Epoch 403, training loss: 1.12844002, training accuracy: 49.353750000000005%, validation loss: 1.14644122, validation accuracy: 48.695%\n",
      "Epoch 404, training loss: 1.12852407, training accuracy: 49.27625%, validation loss: 1.14553976, validation accuracy: 48.730000000000004%\n",
      "Epoch 405, training loss: 1.12861109, training accuracy: 49.293749999999996%, validation loss: 1.14466274, validation accuracy: 48.795%\n",
      "Epoch 406, training loss: 1.12852037, training accuracy: 49.32375%, validation loss: 1.14475667, validation accuracy: 48.735%\n",
      "Epoch 407, training loss: 1.12848139, training accuracy: 49.27375%, validation loss: 1.14637482, validation accuracy: 48.595%\n",
      "Epoch 408, training loss: 1.12854791, training accuracy: 49.26875%, validation loss: 1.14413226, validation accuracy: 48.745%\n",
      "Epoch 409, training loss: 1.12851226, training accuracy: 49.322500000000005%, validation loss: 1.14716899, validation accuracy: 48.58%\n",
      "Epoch 410, training loss: 1.12862360, training accuracy: 49.3725%, validation loss: 1.14492977, validation accuracy: 48.620000000000005%\n",
      "Epoch 411, training loss: 1.12861264, training accuracy: 49.317499999999995%, validation loss: 1.14471078, validation accuracy: 48.845%\n",
      "Epoch 412, training loss: 1.12838709, training accuracy: 49.31875%, validation loss: 1.14456367, validation accuracy: 48.775%\n",
      "Epoch 413, training loss: 1.12845981, training accuracy: 49.33875%, validation loss: 1.14540708, validation accuracy: 48.585%\n",
      "Epoch 414, training loss: 1.12850130, training accuracy: 49.341249999999995%, validation loss: 1.14340293, validation accuracy: 48.605%\n",
      "Epoch 415, training loss: 1.12851322, training accuracy: 49.3525%, validation loss: 1.14584923, validation accuracy: 48.58%\n",
      "Epoch 416, training loss: 1.12824941, training accuracy: 49.44%, validation loss: 1.14550900, validation accuracy: 48.61%\n",
      "Epoch 417, training loss: 1.12844574, training accuracy: 49.3525%, validation loss: 1.14525414, validation accuracy: 48.595%\n",
      "Epoch 418, training loss: 1.12861049, training accuracy: 49.30875%, validation loss: 1.14411581, validation accuracy: 48.699999999999996%\n",
      "Epoch 419, training loss: 1.12841010, training accuracy: 49.3125%, validation loss: 1.14512217, validation accuracy: 48.51%\n",
      "Epoch 420, training loss: 1.12826610, training accuracy: 49.39125%, validation loss: 1.14599383, validation accuracy: 48.835%\n",
      "Epoch 421, training loss: 1.12841797, training accuracy: 49.26375%, validation loss: 1.14561284, validation accuracy: 48.504999999999995%\n",
      "Epoch 422, training loss: 1.12840688, training accuracy: 49.3075%, validation loss: 1.14559722, validation accuracy: 48.63%\n",
      "Epoch 423, training loss: 1.12837720, training accuracy: 49.33125%, validation loss: 1.14617610, validation accuracy: 48.74%\n",
      "Epoch 424, training loss: 1.12832689, training accuracy: 49.38125%, validation loss: 1.14637637, validation accuracy: 48.75%\n",
      "Epoch 425, training loss: 1.12835979, training accuracy: 49.341249999999995%, validation loss: 1.14517736, validation accuracy: 48.695%\n",
      "Epoch 426, training loss: 1.12842381, training accuracy: 49.32375%, validation loss: 1.14494157, validation accuracy: 48.72%\n",
      "Epoch 427, training loss: 1.12847388, training accuracy: 49.3475%, validation loss: 1.14516425, validation accuracy: 48.745%\n",
      "Epoch 428, training loss: 1.12839985, training accuracy: 49.34375%, validation loss: 1.14467263, validation accuracy: 48.595%\n",
      "Epoch 429, training loss: 1.12825429, training accuracy: 49.28875%, validation loss: 1.14497125, validation accuracy: 48.57%\n",
      "Epoch 430, training loss: 1.12865388, training accuracy: 49.3075%, validation loss: 1.14399207, validation accuracy: 48.63%\n",
      "Epoch 431, training loss: 1.12854016, training accuracy: 49.37875%, validation loss: 1.14592981, validation accuracy: 48.64%\n",
      "Epoch 432, training loss: 1.12838519, training accuracy: 49.315%, validation loss: 1.14721382, validation accuracy: 48.585%\n",
      "Epoch 433, training loss: 1.12846017, training accuracy: 49.3%, validation loss: 1.14484191, validation accuracy: 48.635%\n",
      "Epoch 434, training loss: 1.12847435, training accuracy: 49.4275%, validation loss: 1.14584410, validation accuracy: 48.61%\n",
      "Epoch 435, training loss: 1.12843883, training accuracy: 49.37125%, validation loss: 1.14527559, validation accuracy: 48.625%\n",
      "Epoch 436, training loss: 1.12860644, training accuracy: 49.346250000000005%, validation loss: 1.14437056, validation accuracy: 48.725%\n",
      "Epoch 437, training loss: 1.12846911, training accuracy: 49.32%, validation loss: 1.14471436, validation accuracy: 48.715%\n",
      "Epoch 438, training loss: 1.12838542, training accuracy: 49.316250000000004%, validation loss: 1.14529252, validation accuracy: 48.71%\n",
      "Epoch 439, training loss: 1.12844765, training accuracy: 49.36875%, validation loss: 1.14562643, validation accuracy: 48.66%\n",
      "Epoch 440, training loss: 1.12849486, training accuracy: 49.315%, validation loss: 1.14475107, validation accuracy: 48.835%\n",
      "Epoch 441, training loss: 1.12827039, training accuracy: 49.31875%, validation loss: 1.14570367, validation accuracy: 48.625%\n",
      "Epoch 442, training loss: 1.12812603, training accuracy: 49.35125%, validation loss: 1.14528692, validation accuracy: 48.61%\n",
      "Epoch 443, training loss: 1.12845194, training accuracy: 49.317499999999995%, validation loss: 1.14623845, validation accuracy: 48.620000000000005%\n",
      "Epoch 444, training loss: 1.12834883, training accuracy: 49.309999999999995%, validation loss: 1.14551091, validation accuracy: 48.535000000000004%\n",
      "Epoch 445, training loss: 1.12860513, training accuracy: 49.27%, validation loss: 1.14526129, validation accuracy: 48.754999999999995%\n",
      "Epoch 446, training loss: 1.12836111, training accuracy: 49.315%, validation loss: 1.14613044, validation accuracy: 48.77%\n",
      "Epoch 447, training loss: 1.12829041, training accuracy: 49.2925%, validation loss: 1.14570379, validation accuracy: 48.504999999999995%\n",
      "Epoch 448, training loss: 1.12819684, training accuracy: 49.375%, validation loss: 1.14603281, validation accuracy: 48.57%\n",
      "Epoch 449, training loss: 1.12833273, training accuracy: 49.37875%, validation loss: 1.14388621, validation accuracy: 48.625%\n",
      "Epoch 450, training loss: 1.12831461, training accuracy: 49.32%, validation loss: 1.14421260, validation accuracy: 48.730000000000004%\n",
      "Epoch 451, training loss: 1.12851179, training accuracy: 49.33625%, validation loss: 1.14537191, validation accuracy: 48.615%\n",
      "Epoch 452, training loss: 1.12827289, training accuracy: 49.333749999999995%, validation loss: 1.14580226, validation accuracy: 48.695%\n",
      "Epoch 453, training loss: 1.12824214, training accuracy: 49.34375%, validation loss: 1.14433730, validation accuracy: 48.64%\n",
      "Epoch 454, training loss: 1.12834001, training accuracy: 49.35125%, validation loss: 1.14540267, validation accuracy: 48.445%\n",
      "Epoch 455, training loss: 1.12816179, training accuracy: 49.3%, validation loss: 1.14440572, validation accuracy: 48.745%\n",
      "Epoch 456, training loss: 1.12844086, training accuracy: 49.364999999999995%, validation loss: 1.14638209, validation accuracy: 48.64%\n",
      "Epoch 457, training loss: 1.12841392, training accuracy: 49.2525%, validation loss: 1.14677167, validation accuracy: 48.515%\n",
      "Epoch 458, training loss: 1.12831891, training accuracy: 49.34375%, validation loss: 1.14607251, validation accuracy: 48.68%\n",
      "Epoch 459, training loss: 1.12824678, training accuracy: 49.353750000000005%, validation loss: 1.14460886, validation accuracy: 48.775%\n",
      "Epoch 460, training loss: 1.12836659, training accuracy: 49.30125%, validation loss: 1.14548969, validation accuracy: 48.615%\n",
      "Epoch 461, training loss: 1.12822759, training accuracy: 49.32125%, validation loss: 1.14608729, validation accuracy: 48.66%\n",
      "Epoch 462, training loss: 1.12824857, training accuracy: 49.305%, validation loss: 1.14593482, validation accuracy: 48.644999999999996%\n",
      "Epoch 463, training loss: 1.12836850, training accuracy: 49.36875%, validation loss: 1.14579499, validation accuracy: 48.559999999999995%\n",
      "Epoch 464, training loss: 1.12826622, training accuracy: 49.32%, validation loss: 1.14589012, validation accuracy: 48.695%\n",
      "Epoch 465, training loss: 1.12826490, training accuracy: 49.33875%, validation loss: 1.14498556, validation accuracy: 48.695%\n",
      "Epoch 466, training loss: 1.12827969, training accuracy: 49.293749999999996%, validation loss: 1.14460623, validation accuracy: 48.6%\n",
      "Epoch 467, training loss: 1.12836194, training accuracy: 49.34%, validation loss: 1.14656413, validation accuracy: 48.735%\n",
      "Epoch 468, training loss: 1.12837660, training accuracy: 49.2325%, validation loss: 1.14519870, validation accuracy: 48.365%\n",
      "Epoch 469, training loss: 1.12843394, training accuracy: 49.3275%, validation loss: 1.14538741, validation accuracy: 48.695%\n",
      "Epoch 470, training loss: 1.12818611, training accuracy: 49.41125%, validation loss: 1.14574790, validation accuracy: 48.58%\n",
      "Epoch 471, training loss: 1.12834454, training accuracy: 49.28375%, validation loss: 1.14673376, validation accuracy: 48.57%\n",
      "Epoch 472, training loss: 1.12836313, training accuracy: 49.28%, validation loss: 1.14532411, validation accuracy: 48.615%\n",
      "Epoch 473, training loss: 1.12826633, training accuracy: 49.36625%, validation loss: 1.14481199, validation accuracy: 48.730000000000004%\n",
      "Epoch 474, training loss: 1.12834907, training accuracy: 49.286249999999995%, validation loss: 1.14458919, validation accuracy: 48.79%\n",
      "Epoch 475, training loss: 1.12835062, training accuracy: 49.335%, validation loss: 1.14551926, validation accuracy: 48.825%\n",
      "Epoch 476, training loss: 1.12809813, training accuracy: 49.33625%, validation loss: 1.14605653, validation accuracy: 48.730000000000004%\n",
      "Epoch 477, training loss: 1.12829721, training accuracy: 49.38375%, validation loss: 1.14521027, validation accuracy: 48.730000000000004%\n",
      "Epoch 478, training loss: 1.12828863, training accuracy: 49.346250000000005%, validation loss: 1.14566159, validation accuracy: 48.504999999999995%\n",
      "Epoch 479, training loss: 1.12812853, training accuracy: 49.4375%, validation loss: 1.14510763, validation accuracy: 48.42%\n",
      "Epoch 480, training loss: 1.12822568, training accuracy: 49.24375%, validation loss: 1.14485121, validation accuracy: 48.655%\n",
      "Epoch 481, training loss: 1.12814152, training accuracy: 49.31875%, validation loss: 1.14569807, validation accuracy: 48.775%\n",
      "Epoch 482, training loss: 1.12832189, training accuracy: 49.36875%, validation loss: 1.14571071, validation accuracy: 48.625%\n",
      "Epoch 483, training loss: 1.12821293, training accuracy: 49.39125%, validation loss: 1.14586091, validation accuracy: 48.69%\n",
      "Epoch 484, training loss: 1.12810552, training accuracy: 49.3975%, validation loss: 1.14539611, validation accuracy: 48.74%\n",
      "Epoch 485, training loss: 1.12834585, training accuracy: 49.35%, validation loss: 1.14403641, validation accuracy: 48.54%\n",
      "Epoch 486, training loss: 1.12826216, training accuracy: 49.377500000000005%, validation loss: 1.14535713, validation accuracy: 48.655%\n",
      "Epoch 487, training loss: 1.12810063, training accuracy: 49.28875%, validation loss: 1.14501345, validation accuracy: 48.49%\n",
      "Epoch 488, training loss: 1.12821519, training accuracy: 49.37125%, validation loss: 1.14514995, validation accuracy: 48.730000000000004%\n",
      "Epoch 489, training loss: 1.12826920, training accuracy: 49.432500000000005%, validation loss: 1.14536440, validation accuracy: 48.67%\n",
      "Epoch 490, training loss: 1.12800455, training accuracy: 49.325%, validation loss: 1.14578772, validation accuracy: 48.545%\n",
      "Epoch 491, training loss: 1.12820327, training accuracy: 49.2825%, validation loss: 1.14575565, validation accuracy: 48.55%\n",
      "Epoch 492, training loss: 1.12826920, training accuracy: 49.34%, validation loss: 1.14644575, validation accuracy: 48.825%\n",
      "Epoch 493, training loss: 1.12811947, training accuracy: 49.446250000000006%, validation loss: 1.14468837, validation accuracy: 48.525%\n",
      "Epoch 494, training loss: 1.12810326, training accuracy: 49.37125%, validation loss: 1.14433575, validation accuracy: 48.725%\n",
      "Epoch 495, training loss: 1.12823164, training accuracy: 49.27%, validation loss: 1.14536524, validation accuracy: 48.65%\n",
      "Epoch 496, training loss: 1.12813842, training accuracy: 49.37625%, validation loss: 1.14527893, validation accuracy: 48.725%\n",
      "Epoch 497, training loss: 1.12810743, training accuracy: 49.36%, validation loss: 1.14605343, validation accuracy: 48.55%\n",
      "Epoch 498, training loss: 1.12807631, training accuracy: 49.322500000000005%, validation loss: 1.14585483, validation accuracy: 48.485%\n",
      "Epoch 499, training loss: 1.12806344, training accuracy: 49.33125%, validation loss: 1.14639544, validation accuracy: 48.595%\n",
      "Epoch 500, training loss: 1.12817895, training accuracy: 49.30875%, validation loss: 1.14496648, validation accuracy: 48.76%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500 # Number of times you go through the whole dataset\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # TRAINING\n",
    "    model.train()\n",
    "    training_total_correct = 0\n",
    "    training_losses = list()\n",
    "    for batch in train_loader:\n",
    "        \n",
    "        x, y = batch # extracted from the batch \n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        # step 1: forward pass \n",
    "        prob = model(x) \n",
    "        \n",
    "        output = prob\n",
    "        target = y\n",
    "        \n",
    "        # step 2: compute objective function - measuring distance between the output of the network vs actual answer \n",
    "        obj_func = loss(output, target)\n",
    "        \n",
    "        # step 3: clear the gradients \n",
    "        model.zero_grad()\n",
    "        \n",
    "        # step 4: accumulate partial derivatives of obj_func wrt parameters \n",
    "        obj_func.backward()\n",
    "        \n",
    "        # step 5: step in the opposite direction of the gradient \n",
    "        optimizer.step()\n",
    "\n",
    "        training_losses.append(obj_func.item())\n",
    "        \n",
    "        max_prob, max_ind = torch.max(output, 1)\n",
    "        for ind in range(len(max_ind)):\n",
    "            if torch.equal(max_ind[ind], y[ind]):\n",
    "                training_total_correct += 1    \n",
    "    \n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "\n",
    "    validation_total_correct = 0\n",
    "    validation_losses = list()\n",
    "    for batch in val_loader:\n",
    "        \n",
    "        x, y = batch # extracted from the batch \n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        # step 1: forward pass \n",
    "        with torch.no_grad():\n",
    "            prob = model(x) \n",
    "        \n",
    "        output = prob\n",
    "        target = y\n",
    "        \n",
    "        # step 2: compute objective function - measuring distance between the output of the network vs actual answer \n",
    "        obj_func = loss(output, target)\n",
    "        validation_losses.append(obj_func.item())\n",
    "        \n",
    "        max_prob, max_ind = torch.max(output, 1)\n",
    "        \n",
    "        for ind in range(len(max_ind)):\n",
    "            if torch.equal(max_ind[ind], y[ind]):\n",
    "                validation_total_correct += 1\n",
    "    training_accuracy = (training_total_correct/len(train))*100  \n",
    "    validation_accuracy = (validation_total_correct/len(val))*100   \n",
    "    \n",
    "    print(f'Epoch {epoch + 1}, training loss: {torch.tensor(training_losses).mean():.8f}, training accuracy: {training_accuracy}%, validation loss: {torch.tensor(validation_losses).mean():.8f}, validation accuracy: {validation_accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
