{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pickle import load\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import array, stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fading = 0\n",
    "num_ant = 2\n",
    "SNR_dB = 5\n",
    "bit_codebook = 1\n",
    "max_iter = 100000\n",
    "num_classes = 2**bit_codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'datasets'\n",
    "if not os.path.exists(dir_name):\n",
    "    os.makedirs(dir_name)\n",
    "file_name = f'{dir_name}/{fading}_precoder_data_{num_ant}_ant_SNR_{SNR_dB}dB_{bit_codebook}_bit_codebk'\n",
    "print(file_name)\n",
    "with open(f'{file_name}.pkl', 'rb') as f:\n",
    "    precoders, labels = load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test plots\n",
    "for i in range(2):\n",
    "    plt.scatter(precoders[i][0::2], precoders[i][1::2])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precoder_data = stack(precoders, axis=0)\n",
    "precoder_labels = array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrecoderDataset(Dataset):\n",
    "    def __init__(self, data, target, transform=None):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.target = torch.from_numpy(target).long()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "precoder_dataset = PrecoderDataset(precoder_data, precoder_labels)\n",
    "train, val = random_split(precoder_dataset, [int(0.8*max_iter), int(0.2*max_iter)])\n",
    "train_loader = DataLoader(\n",
    "    train,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "# increase batch size\n",
    "val_loader = DataLoader(\n",
    "    val,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn \n",
    "from torch import optim \n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        # define layers and activation function as class parameters\n",
    "        self.linear1 = nn.Linear(input_size, 8)\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "        self.linear2 = nn.Linear(8, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # define NN connections here, output of last layer is pred\n",
    "        x1 = self.linear1(x)\n",
    "        x2 = self.drop(x1)\n",
    "        pred = self.linear2(x2)\n",
    "        return pred\n",
    "\n",
    "input_size = 2*num_ant*num_ant\n",
    "output_size = num_classes\n",
    "model = Model(input_size, output_size)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 500 # Number of times you go through the whole dataset\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # TRAINING\n",
    "    model.train()\n",
    "    training_total_correct = 0\n",
    "    training_losses = list()\n",
    "    for batch in train_loader:\n",
    "        \n",
    "        x, y = batch # extracted from the batch \n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        # step 1: forward pass \n",
    "        prob = model(x) \n",
    "        \n",
    "        output = prob\n",
    "        target = y\n",
    "        \n",
    "        # step 2: compute objective function - measuring distance between the output of the network vs actual answer \n",
    "        obj_func = loss(output, target)\n",
    "        \n",
    "        # step 3: clear the gradients \n",
    "        model.zero_grad()\n",
    "        \n",
    "        # step 4: accumulate partial derivatives of obj_func wrt parameters \n",
    "        obj_func.backward()\n",
    "        \n",
    "        # step 5: step in the opposite direction of the gradient \n",
    "        optimizer.step()\n",
    "\n",
    "        training_losses.append(obj_func.item())\n",
    "        \n",
    "        max_prob, max_ind = torch.max(output, 1)\n",
    "#         print(len(max_ind))\n",
    "        for ind in range(len(max_ind)):\n",
    "#             print(max_ind[ind], y[ind])\n",
    "            if torch.equal(max_ind[ind], y[ind]):\n",
    "                training_total_correct += 1\n",
    "#     print(training_total_correct)  \n",
    "#     print(f'Epoch {epoch + 1}, training loss: {torch.tensor(training_losses).mean():.8f}')\n",
    "    \n",
    "    \n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "\n",
    "    validation_total_correct = 0\n",
    "    validation_losses = list()\n",
    "    for batch in val_loader:\n",
    "        \n",
    "        x, y = batch # extracted from the batch \n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        # step 1: forward pass \n",
    "        with torch.no_grad():\n",
    "            prob = model(x) \n",
    "        \n",
    "        output = prob\n",
    "        target = y\n",
    "        \n",
    "        # step 2: compute objective function - measuring distance between the output of the network vs actual answer \n",
    "        obj_func = loss(output, target)\n",
    "        validation_losses.append(obj_func.item())\n",
    "        \n",
    "        max_prob, max_ind = torch.max(output, 1)\n",
    "        \n",
    "        for ind in range(len(max_ind)):\n",
    "#             print(max_ind[ind], y[ind])\n",
    "            if torch.equal(max_ind[ind], y[ind]):\n",
    "                validation_total_correct += 1\n",
    "#     print(len(train), len(val))          \n",
    "    training_accuracy = (training_total_correct/len(train))*100  \n",
    "    validation_accuracy = (validation_total_correct/len(val))*100   \n",
    "    \n",
    "    print(f'Epoch {epoch + 1}, training loss: {torch.tensor(training_losses).mean():.8f}, training accuracy: {training_accuracy}%, validation loss: {torch.tensor(validation_losses).mean():.8f}, validation accuracy: {validation_accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
